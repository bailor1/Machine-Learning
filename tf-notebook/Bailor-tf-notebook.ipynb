{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC 478 Machine Learning\n",
    "\n",
    "\n",
    "## Getting Started with Tensorflow, Keras, and Tensorboard\n",
    "\n",
    "### Instructor: Fereydoon Vafaei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sam Bailor - VK96692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps you get started with Tensorflow/Keras API. This notebook assumes you have installed Tensorflow 2.<br>\n",
    "If you have not installed Tensorflow 2 or have installed previous versions of Tensorflow, you need to [install Tensorflow 2](https://www.tensorflow.org/install) before proceeding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Installation Verification](#Installation-Verification)\n",
    "* [A Simple Regression NN](#A-One-Layer-One-Neuron-Regression-Neural-Network-using-Tensorflow/Keras)\n",
    "* [A Multi-layer NN on MNIST Dataset](#A-Multi-Layer-NN-for-Multi-Class-Classification-on-MNIST-Dataset)\n",
    "* [Eager Execution in Tensorflow-2](#Eager-Execution-in-Tensorflow-2)\n",
    "* [Creating the model using the Sequential API](#Creating-the-model-using-the-Sequential-API)\n",
    "* [Fashion MNIST Dataset](#Fashion-MNIST-Dataset)\n",
    "* [Using Code Examples from keras.io](#Using-Code-Examples-from-keras.io)\n",
    "* [California House Pricing](#California-House-Pricing)\n",
    "* [Callbacks](#Callbacks)\n",
    "* [Tensorboard](#Tensorboard)\n",
    "* [Exercise-1](#Exercise-1)\n",
    "* [Exercise-2](#Exercise-2)\n",
    "* [References](#References)\n",
    "* [Grading and Submission](#Grading-and-Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is one of the most popular ML/DL frameworks. Watch this video first:\n",
    "\n",
    "https://www.youtube.com/watch?v=744f60NyAgc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very Important Note**:\n",
    "\n",
    "**RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO even if you've completed the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your tf version should be 2.0.0 or higher\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A One-Layer One-Neuron Regression Neural Network using Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first example is a regression NN with only one layer and one neuron to recognize the pattern of a sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 4.8391\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9805\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.3015\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7637\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3372\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9984\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7285\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.5129\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3402\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2012\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0889\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9975\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9227\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.8611\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8098\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7667\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7302\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6988\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6716\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6477\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6264\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6073\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5899\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5739\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5591\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5452\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5321\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5197\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5078\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4965\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4855\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4750\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4648\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4549\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4453\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4359\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4268\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4179\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4092\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4007\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3924\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3843\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3764\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3686\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3610\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3536\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3463\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3392\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3322\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.3254\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3187\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3121\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3057\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2994\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2933\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2872\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2756\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2699\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2644\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2589\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2536\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2484\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2433\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2383\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2334\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2286\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2239\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2193\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2148\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2104\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2061\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2018\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1977\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1936\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1897\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1858\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1819\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1782\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1745\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1710\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1675\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1640\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.1606\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1573\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1541\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.1509\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1478\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1448\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1418\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1389\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1361\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1333\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1305\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.1279\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1252\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1227\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1201\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1177\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1153\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1129\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1106\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1083\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1061\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1039\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1018\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0997\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0976\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0956\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0937\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0917\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0898\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0880\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0862\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0844\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0827\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0810\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0793\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0777\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0761\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0745\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0730\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0715\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0700\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0686\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0672\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0645\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0631\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0618\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0606\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0593\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0581\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0569\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0557\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0546\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0535\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0524\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0513\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0502\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0492\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0482\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0472\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0462\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0453\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0444\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0435\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0426\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0417\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0408\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0400\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0392\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0384\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0376\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0368\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0360\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0353\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0346\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0339\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0332\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0325\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.0318\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0312\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0305\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0299\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0293\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0287\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0281\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0275\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0270\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0264\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0259\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0253\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0248\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0238\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0233\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0224\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0219\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0215\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0154\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 202/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0133\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0130\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0128\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0125\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0123\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0120\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0118\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0115\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0113\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0110\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0108\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0106\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0104\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0086\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0084\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0083\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0081\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0079\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0076\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0074\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0070\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0067\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0066\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0064\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0063\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0062\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0060\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0059\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0058\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0055\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0053\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0052\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0051\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0050\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0048\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0047\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0045\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0044\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0041\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0040\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0039\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0038\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0038\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0036\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0035\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0034\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.0033\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0032\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0032\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0030\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0028\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0027\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0026\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0026\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0025\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0024\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0023\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0022\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0021\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.0021\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0020\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0019\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.0019\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0018\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0018\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0017\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0016\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0016\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0014\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0013\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0011\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9434e-04\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.7392e-04\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5391e-04\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3432e-04\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1513e-04\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 8.9633e-04\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7792e-04\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5989e-04\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.4222e-04\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2492e-04\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0798e-04\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.9138e-04\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.7512e-04\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.5920e-04\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4361e-04\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2833e-04\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1337e-04\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9872e-04\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8437e-04\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7031e-04\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.5654e-04\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.4306e-04\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.2985e-04\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1691e-04\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.0424e-04\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.9182e-04\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.7967e-04\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.6776e-04\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.5610e-04\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4468e-04\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3349e-04\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2253e-04\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1180e-04\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.0128e-04\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 502us/step - loss: 4.9099e-04\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8090e-04\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.7103e-04\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6135e-04\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5187e-04\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.4259e-04\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.3350e-04\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2460e-04\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.1588e-04\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0733e-04\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.9896e-04\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.9077e-04\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8274e-04\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7488e-04\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6718e-04\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5964e-04\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.5225e-04\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.4502e-04\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3793e-04\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3099e-04\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2419e-04\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1753e-04\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1101e-04\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.0462e-04\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9837e-04\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.9224e-04\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8623e-04\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.8035e-04\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7459e-04\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6895e-04\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6343e-04\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5802e-04\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5272e-04\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4753e-04\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4244e-04\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3746e-04\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3259e-04\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2781e-04\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.2313e-04\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1855e-04\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1405e-04\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0966e-04\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.0535e-04\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0113e-04\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9700e-04\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9296e-04\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8899e-04\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8511e-04\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8131e-04\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7759e-04\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7394e-04\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7037e-04\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6686e-04\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6344e-04\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6008e-04\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5679e-04\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5357e-04\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5042e-04\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4733e-04\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4430e-04\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4134e-04\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3843e-04\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3559e-04\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3281e-04\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3008e-04\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2741e-04\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2479e-04\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2222e-04\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1972e-04\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1726e-04\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1485e-04\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1249e-04\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1018e-04\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0792e-04\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0570e-04\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0353e-04\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0140e-04\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.9319e-05\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7278e-05\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5280e-05\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3323e-05\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1406e-05\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9528e-05\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7690e-05\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5888e-05\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4125e-05\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2398e-05\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0705e-05\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9048e-05\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7423e-05\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5832e-05\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4275e-05\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2749e-05\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1255e-05\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9792e-05\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8358e-05\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6953e-05\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5578e-05\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4231e-05\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2912e-05\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1620e-05\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.0353e-05\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9114e-05\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7900e-05\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6710e-05\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.5546e-05\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4404e-05\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.3287e-05\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2192e-05\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1120e-05\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.0071e-05\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9041e-05\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8033e-05\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7048e-05\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6080e-05\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5134e-05\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4208e-05\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3299e-05\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2410e-05\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1538e-05\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0685e-05\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 3.9850e-05\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9032e-05\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 3.8230e-05\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.7445e-05\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.6676e-05\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5923e-05\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5185e-05\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.4462e-05\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3754e-05\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3061e-05\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.2382e-05\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1717e-05\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1065e-05\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.0427e-05\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.9801e-05\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9189e-05\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.8590e-05\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8003e-05\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7427e-05\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6864e-05\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6312e-05\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5771e-05\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5242e-05\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4724e-05\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.4216e-05\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.3718e-05\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3231e-05\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2754e-05\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2287e-05\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1829e-05\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1381e-05\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0941e-05\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0511e-05\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0090e-05\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9678e-05\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9273e-05\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8877e-05\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8490e-05\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8109e-05\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7738e-05\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7373e-05\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7016e-05\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6667e-05\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6325e-05\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.5990e-05\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5661e-05\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5340e-05\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5024e-05\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4716e-05\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4414e-05\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4118e-05\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3827e-05\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3543e-05\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3265e-05\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2993e-05\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2726e-05\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2465e-05\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2209e-05\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1958e-05\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.1713e-05\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1472e-05\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1236e-05\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1005e-05\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0779e-05\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0558e-05\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0341e-05\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0129e-05\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9204e-06\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.7164e-06\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5173e-06\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.3216e-06\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 9.1299e-06\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9425e-06\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7588e-06\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5792e-06\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4031e-06\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2303e-06\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0616e-06\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8957e-06\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7335e-06\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5747e-06\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4191e-06\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 7.2667e-06\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1176e-06\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9711e-06\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8280e-06\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6874e-06\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.5502e-06\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.4157e-06\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2840e-06\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.1546e-06\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0284e-06\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.9046e-06\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7831e-06\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6645e-06\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5478e-06\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4338e-06\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.3225e-06\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2131e-06\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1060e-06\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0012e-06\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8985e-06\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.7977e-06\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.6992e-06\n",
      "Epoch 588/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6025e-06\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5083e-06\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4157e-06\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3248e-06\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2362e-06\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1493e-06\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0639e-06\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.9805e-06\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8984e-06\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8186e-06\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.7402e-06\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6632e-06\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5882e-06\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5143e-06\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.4421e-06\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.3713e-06\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3023e-06\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2343e-06\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1677e-06\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1030e-06\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0391e-06\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9767e-06\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9155e-06\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8557e-06\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7969e-06\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7394e-06\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6830e-06\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6279e-06\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5740e-06\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.5213e-06\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4693e-06\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4187e-06\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3690e-06\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3203e-06\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2725e-06\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2259e-06\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1802e-06\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1355e-06\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0915e-06\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0485e-06\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0066e-06\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9654e-06\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9249e-06\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8855e-06\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8468e-06\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8088e-06\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7715e-06\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7353e-06\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6996e-06\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6647e-06\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6305e-06\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5969e-06\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5641e-06\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.5321e-06\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5007e-06\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4698e-06\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4397e-06\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4100e-06\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3811e-06\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.3526e-06\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3248e-06\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2977e-06\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2710e-06\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2449e-06\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2193e-06\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1943e-06\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1698e-06\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1458e-06\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1221e-06\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0992e-06\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0765e-06\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0545e-06\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0328e-06\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.0115e-06\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9070e-07\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.7045e-07\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5049e-07\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3095e-07\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1183e-07\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9323e-07\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7482e-07\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5685e-07\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3927e-07\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2191e-07\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0501e-07\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8850e-07\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7240e-07\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5645e-07\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.4089e-07\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2569e-07\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.1080e-07\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9620e-07\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8197e-07\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6788e-07\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5429e-07\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4073e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2754e-07\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.1466e-07\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0211e-07\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8960e-07\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7752e-07\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6572e-07\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.5412e-07\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4269e-07\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3152e-07\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2065e-07\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0988e-07\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9945e-07\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8924e-07\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7911e-07\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6933e-07\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5966e-07\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5017e-07\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4101e-07\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3188e-07\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2300e-07\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1438e-07\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0580e-07\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9746e-07\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.8936e-07\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8139e-07\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7343e-07\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6582e-07\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5825e-07\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5093e-07\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4371e-07\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.3661e-07\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2978e-07\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2295e-07\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1637e-07\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0984e-07\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.0351e-07\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.9721e-07\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.9116e-07\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8515e-07\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7926e-07\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7354e-07\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6797e-07\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6240e-07\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.5700e-07\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.5177e-07\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4657e-07\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4156e-07\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3654e-07\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3167e-07\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2698e-07\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2225e-07\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1775e-07\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1330e-07\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0890e-07\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0461e-07\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0042e-07\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9620e-07\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9223e-07\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8822e-07\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.8443e-07\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8060e-07\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7695e-07\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7332e-07\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6975e-07\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6625e-07\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6287e-07\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5952e-07\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5617e-07\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5298e-07\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4982e-07\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4675e-07\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4373e-07\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4077e-07\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3786e-07\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3502e-07\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3226e-07\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2957e-07\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2691e-07\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2432e-07\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2175e-07\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1926e-07\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1678e-07\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1437e-07\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1206e-07\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0972e-07\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0752e-07\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0532e-07\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0313e-07\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0103e-07\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8958e-08\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6924e-08\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.4930e-08\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.2941e-08\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1075e-08\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9201e-08\n",
      "Epoch 779/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7351e-08\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.5563e-08\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3779e-08\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2064e-08\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0357e-08\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8731e-08\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7125e-08\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5539e-08\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3977e-08\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2505e-08\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0981e-08\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9544e-08\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8117e-08\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6704e-08\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5326e-08\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3989e-08\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2680e-08\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1406e-08\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0132e-08\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8929e-08\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7721e-08\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6514e-08\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5348e-08\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4214e-08\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3129e-08\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2021e-08\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0970e-08\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9917e-08\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8902e-08\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7877e-08\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6914e-08\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5935e-08\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5006e-08\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4078e-08\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3173e-08\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2277e-08\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1404e-08\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0532e-08\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9695e-08\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8886e-08\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8089e-08\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7324e-08\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6550e-08\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5813e-08\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.5065e-08\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.4348e-08\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3642e-08\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2962e-08\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2271e-08\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.1605e-08\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.0972e-08\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.0345e-08\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9725e-08\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9112e-08\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8510e-08\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7914e-08\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7369e-08\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 2.6780e-08\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6252e-08\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5728e-08\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.5172e-08\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.4658e-08\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4152e-08\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3648e-08\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3182e-08\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.2700e-08\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2212e-08\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1762e-08\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1312e-08\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0890e-08\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0482e-08\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0055e-08\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9636e-08\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9251e-08\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8859e-08\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.8465e-08\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8087e-08\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7721e-08\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7366e-08\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.7011e-08\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6664e-08\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6312e-08\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5975e-08\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.5663e-08\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5331e-08\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5008e-08\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4707e-08\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.4410e-08\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4109e-08\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3821e-08\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3529e-08\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3250e-08\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2993e-08\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2734e-08\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2464e-08\n",
      "Epoch 874/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2221e-08\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1960e-08\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1714e-08\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1478e-08\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 1.1253e-08\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1018e-08\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0798e-08\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0568e-08\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0349e-08\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0140e-08\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9432e-09\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7303e-09\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5209e-09\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3391e-09\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1315e-09\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.9488e-09\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7645e-09\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5875e-09\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.4135e-09\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2538e-09\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.0809e-09\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.9116e-09\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7565e-09\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5966e-09\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.4385e-09\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.2885e-09\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1453e-09\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0058e-09\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8540e-09\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7151e-09\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5824e-09\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4514e-09\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3192e-09\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1955e-09\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0655e-09\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9402e-09\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8130e-09\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6920e-09\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.5764e-09\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4681e-09\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3537e-09\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2376e-09\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1228e-09\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0265e-09\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9159e-09\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8211e-09\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.7240e-09\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.6273e-09\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5212e-09\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4406e-09\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3511e-09\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2613e-09\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1765e-09\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0843e-09\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9962e-09\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9264e-09\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8421e-09\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7638e-09\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6906e-09\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.6108e-09\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5425e-09\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4645e-09\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3957e-09\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3329e-09\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2576e-09\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.1941e-09\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1335e-09\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0679e-09\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0065e-09\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.9455e-09\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8889e-09\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8325e-09\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7736e-09\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7149e-09\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6606e-09\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6065e-09\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5500e-09\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4970e-09\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4479e-09\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3943e-09\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3433e-09\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3020e-09\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2503e-09\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2034e-09\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1610e-09\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1124e-09\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0671e-09\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0208e-09\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9815e-09\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.9436e-09\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9033e-09\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8639e-09\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8279e-09\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7859e-09\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.7503e-09\n",
      "Epoch 969/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7128e-09\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6759e-09\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6438e-09\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6101e-09\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5790e-09\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5479e-09\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5138e-09\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4833e-09\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4513e-09\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4263e-09\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3950e-09\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3662e-09\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3358e-09\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3077e-09\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2849e-09\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 503us/step - loss: 1.2624e-09\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2351e-09\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2082e-09\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1863e-09\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.1646e-09\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1363e-09\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1149e-09\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0884e-09\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0696e-09\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0522e-09\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0281e-09\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0088e-09\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9195e-10\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.7406e-10\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 9.5530e-10\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 9.3042e-10\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1314e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f8fe201b80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple linear regression NN with one layer\n",
    "\n",
    "# build a one-layer one-neuron/unit NN, with one dimension/input_shape\n",
    "layer_1 = keras.layers.Dense(units=1, input_shape=[1])\n",
    "model = tf.keras.Sequential([layer_1])\n",
    "\n",
    "# compile/configure model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error') # 'mse'\n",
    "\n",
    "# data: y = 2x - 1\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float) \n",
    "\n",
    "# train NN - 1 epoch is one pass over the entire dataset\n",
    "# after each epoch, the connection weights/model parameters are updated to minimize the loss function\n",
    "model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred when x=10.0 [[18.999908]]\n",
      "Parameters: [array([[1.9999869]], dtype=float32), array([-0.9999605], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# using NN, predict y when x=10.0: 2(10) - 1 = 19\n",
    "print(\"y_pred when x=10.0\", model.predict([10.0]))\n",
    "\n",
    "print(\"Parameters: {}\".format(layer_1.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Multi-Layer NN for Multi-Class Classification on MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Convert the samples from integers to floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14901961, 0.74901961, 0.54117647, 0.09411765, 0.09411765,\n",
       "        0.42352941, 0.54117647, 0.13333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2745098 , 0.98823529, 0.98823529, 0.99215686, 0.98823529,\n",
       "        0.98823529, 0.98823529, 0.98823529, 0.63529412, 0.34509804,\n",
       "        0.05098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2       , 0.94117647, 0.98823529, 0.99215686, 0.94117647,\n",
       "        0.71764706, 0.71764706, 0.96470588, 0.99215686, 0.98823529,\n",
       "        0.79215686, 0.55686275, 0.02745098, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14509804, 0.38431373, 0.82745098, 0.80784314,\n",
       "        0.        , 0.        , 0.16470588, 0.42745098, 0.69411765,\n",
       "        0.98823529, 0.98823529, 0.82745098, 0.16862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.07058824,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "        0.21176471, 0.70196078, 0.98823529, 0.8627451 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16862745, 0.94509804, 1.        , 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.90196078, 0.99215686, 0.36078431,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26666667, 0.96470588, 0.96862745, 0.2627451 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5254902 , 0.98823529, 0.36862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.45490196, 0.97254902, 0.78431373, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05098039, 0.38039216,\n",
       "        0.87058824, 0.75294118, 0.04313725, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14901961, 0.38823529, 0.81568627, 0.89019608,\n",
       "        0.68235294, 0.06666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.81176471, 0.98823529, 0.92941176, 0.34509804,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31372549, 0.79215686, 0.99215686, 0.95686275,\n",
       "        0.81176471, 0.31372549, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04313725, 0.37647059, 0.98823529,\n",
       "        0.98823529, 0.95686275, 0.28627451, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
       "        0.78039216, 0.97647059, 0.99215686, 0.50196078, 0.03529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4627451 , 0.97254902, 0.99215686, 0.44313725,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.45098039, 0.99215686, 0.94117647,\n",
       "        0.19607843, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.98823529,\n",
       "        0.27058824, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99215686, 0.90588235,\n",
       "        0.14509804, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-layer NN for multi-class classification\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer, flatten dimensions since input is an image\n",
    "  tf.keras.layers.Dense(128, activation='relu'), # hidden layer with 128 neurons, decided by trial and error fine tuning\n",
    "  tf.keras.layers.Dropout(0.2), # dropout is a regularization technique\n",
    "  tf.keras.layers.Dense(10, activation='softmax')]) # output layer has 10 neurons for 10 classes, & softmax for multiclass task\n",
    "\n",
    "# compile model for multi-class classification\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', # loss='SparseCategoricalCrossentropy'\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use `loss='sparse_categorical_crossentropy'` loss function when there are two or more label classes. `tf` expects labels to be provided as integers. If you want to provide labels using `one-hot` representation, use `CategoricalCrossentropy` loss.\n",
    "\n",
    "> Read more about the [`SparseCategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) and [`CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) in their tf documentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 682us/step - loss: 0.4816 - accuracy: 0.8601\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 675us/step - loss: 0.1535 - accuracy: 0.9550\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 683us/step - loss: 0.1111 - accuracy: 0.9671\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 687us/step - loss: 0.0880 - accuracy: 0.9731\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 679us/step - loss: 0.0713 - accuracy: 0.9779\n",
      "313/313 - 0s - loss: 0.0759 - accuracy: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07587592303752899, 0.9754999876022339]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train NN\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# test NN\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution in Tensorflow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2 has this new capability of [\"Eager Execution\"](https://www.tensorflow.org/guide/eager) which makes it more convenient to work with tensors and graph computations. See examples below and compare it with chapter 9 of the 1st edition which uses Session() and Run() to execute these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.Variable(4, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'x:0' shape=() dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'y:0' shape=() dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(x.numpy())\n",
    "print(y.numpy())\n",
    "print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets review the steps in building a neural network! Here is a classification MLP with two hidden\n",
    "layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a NN for MNIST\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # the input layer of images\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # the first hidden layer with 300 neurons\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # the 2nd hidden layer with 100 neurons\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # the output layer: it's a 10-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go through this code line by line:\n",
    "- The first line creates a Sequential model. This is the simplest kind of Keras model for neural networks that are just composed of a single stack of layers connected sequentially. This is called the Sequential API.\n",
    "\n",
    "- Next, we build the first layer and add it to the model. It is a Flatten layer whose role is to convert each input image into a 1D array: if it receives input data X , it computes `X.reshape(-1, 1)`. This layer does not have any parameters; it is just there to do some simple preprocessing. Since it is the first layer in the model, you should specify the `input_shape` , which doesnt include the batch size, only the shape of the instances. Alternatively, you could add a `keras.layers.InputLayer` as the first layer, setting `input_shape=[28,28]`\n",
    "\n",
    "- Next we add a Dense hidden layer (fully connected) with 300 neurons. It will use the ReLU activation function. Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron). When it receives some input data, it computes Equation 10-2.\n",
    "\n",
    "$$h_{\\mathbf{W}, \\mathbf{b}}(\\mathbf{X}) = \\phi (\\mathbf{X} \\mathbf{W} + \\mathbf{b})$$\n",
    "\n",
    "- Then we add a second Dense hidden layer with 100 neurons, also using the ReLU activation function.\n",
    "\n",
    "- Finally, we add a Dense output layer with 10 neurons (one per class), using the\n",
    "softmax activation function (because the classes are exclusive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Specifying `activation=\"relu\"` is equivalent to specifying `activation=keras.activations.relu`. Other activation functions are available in the keras.activations package. See https://keras.io/activations/ for the full list.\n",
    "\n",
    "> Instead of adding the layers one by one as we just did, you can pass a list of layers when creating the Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is [another example of image classification](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6000 images with dimensions 28 x 28\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD4CAYAAACE9dGgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdDklEQVR4nO3dfXBc5ZXn8e+RLMm2LL9hYww4MRCTYJLFZB0gMJUhYSZAKjWGSUhBzTJODTVmd2EnTPEHhJ2tsDXFFpUNsKnJwI4JbJwqCOsJMDAMFV4cEkIyvBjj4LclNtjBxsavYBvbsqXus3/01dCydM+9UrfUfc3vQ3WpdU8/fR+3pMO9zz33eczdEREpqpZGd0BEpBZKYiJSaEpiIlJoSmIiUmhKYiJSaGNGc2ft1uFj6RzNXYp8pHRzgCN+2Gp5j4u/2Om795RyvfbV1w8/5e6X1LK/WtWUxMzsEuD7QCvwQ3e/PXr9WDo51y6qZZciEnjJl9X8Hrv3lHj5qY/lem3rzPXTat5hjYZ9OmlmrcDfA5cCc4GrzGxuvTomIo3hQDnnf1nMbJaZPWdm68xsjZl9K9l+q5m9Y2Yrk8dXqtp828w2mNkbZnZx1j5qORI7B9jg7m8lO34IWACsreE9RaTBHKfH851O5tAL3OjuK8ysC3jVzJ5JYne5+/eqX5wcCF0JnAmcCDxrZqe7p3eoloH9k4DNVd9vSbb1Y2aLzGy5mS3v4XANuxOR0VKvIzF33+buK5Ln+4F1DJInqiwAHnL3w+6+EdhA5YApVS1JbLDBwwH3MLn7Ynef7+7z2+ioYXciMhocp+T5HsC0voOU5LEo7X3NbDZwNvBSsul6M3vdzO43synJtlwHR9VqSWJbgFlV358MbK3h/USkSZTxXA9gV99BSvJYPNj7mdkE4GHgBnffB9wDnAbMA7YBd/S9dJDm4Q3etSSxV4A5ZnaKmbVTOY99vIb3E5Em4EAJz/XIw8zaqCSwB9z9EQB33+7uJXcvA/fy4SnjkA+Ohp3E3L0XuB54isp57lJ3XzPc9xOR5jGEI7GQmRlwH7DO3e+s2j6z6mWXA6uT548DV5pZh5mdAswBXo72UVOdmLs/CTxZy3uISHNxoKd+U3RdAFwNrDKzlcm2W6iUZM1LdrcJuBbA3deY2VIqVQ69wHXRlUkY5Yp9EWl+PoRTxcz3cn+Bwce5Ug9+3P024La8+1ASE5H+HEoFmitVSUxE+qlU7BeHkpiIHMUoDXoG2JyUxESkn8rAvpKYiBRUpU5MSUxECqysIzERKSodiYlIoTlGqUAz1yuJicgAOp0UkcJyjCPe2uhu5KYkJiL9VIpddTopIgWmgX1pHpbxy1jjbAWtx00N4+9dfHpqbOKDL9a076x/m41pS415z5Ha9l2rrJ9LpH4zTKS8vVFyHYmJSIGVdSQmIkVVGdgvTmooTk9FZFRoYF9ECq+kOjERKSpV7ItI4ZV1dVJEiqpyA7iSmDQJa41vH/He3jDeMm9uGF937YS4/aH0WNuBcHV6xhyKJ0lue3p5GK+pFiyrBi3jc8XiJFBL32xM8Gcb/zhzcYwe3XYkIkXljopdRaTITMWuIlJcjo7ERKTgNLAvIoXlmCZFFJHiqizZVpzUUJyeisgo0eK50kTCmiKy68Q2Xzw5jP/Z538Vxn+989TU2O87Tgjb+rgwzJg/+nwYP/3ud1JjvZvejt88Y86urM8tS+uUKenBUilsW9q3Lz1Yh6nGnI9Qxb6ZbQL2AyWg193n16NTItJYH7UjsS+6+646vI+INAF3++gciYnIsacysP/Rue3IgafNzIF/cPfFR7/AzBYBiwDGMr7G3YnIyCvWHPu19vQCd/8scClwnZl94egXuPtid5/v7vPb6KhxdyIy0ioD+5brkcXMZpnZc2a2zszWmNm3ku1TzewZM1uffJ1S1ebbZrbBzN4ws4uz9lFTEnP3rcnXHcCjQDwtgYgUQomWXI8ceoEb3f0M4DwqBztzgZuBZe4+B1iWfE8SuxI4E7gEuNvMwnPbYScxM+s0s66+58CXgdXDfT8RaQ59Ffv1OBJz923uviJ5vh9YB5wELACWJC9bAlyWPF8APOTuh919I7CBjIOjWsbEZgCPWmXepTHAg+7+sxreT0ZAubu7pvZHzv4gjH99Ujyn19iWntTYL1vi+cLe+fmsMF76d3Hffn9nV2qs/Nr5YdvjVse1WhNf2xbGd33hpDC+89+nF3TNyFiOc8qzb6bGbE99rtUNYaGQaWZW/UuweLCxcQAzmw2cDbwEzHD3bVBJdGZ2fPKyk4DqT2BLsi3VsP/F7v4WcNZw24tIc3KHnnLuJLYrT32omU0AHgZucPd9lj7p5GCBsIRXJRYi0k/ldLJ+VyfNrI1KAnvA3R9JNm83s5nJUdhMYEeyfQtQfQh+MrA1ev/iXEcVkVFTSu6fzHpkscoh133AOne/syr0OLAweb4QeKxq+5Vm1mFmpwBzgJejfehITET66SuxqJMLgKuBVWa2Mtl2C3A7sNTMrgHeBq4AcPc1ZrYUWEvlyuZ17h4OUCqJichR6nc66e4vMPg4F8BFKW1uA27Luw8lMREZQHPsy+iKlhfLmFLmg2+cF8b/fO4vwvibPdPD+Mnte1JjV5z4atiW/xDHf/DGH4bxA29NSo21dMafy7vnxUci7yyI/93eE0/VM2VF+p9ey8LtYdt9R9KnNyotq/2umMrVyY/OvZMicozR9NQiUng6nRSRwqrz1ckRpyQmIgNoUkQRKSx3o1dJTESKTKeTIlJYGhOToYvqvEbYeTeFt6XxxQlra3r/k4IJCA54e9j2/VJnGP/O3H8J4ztPT5+KJ2tx2B+uj6fq+SCoQQNo7Y1/puf9xWupsa9NfSVs+92HP5Maa/EDYdu8lMREpLBUJyYihac6MREpLHfozT8pYsMpiYnIADqdFJHC0piYiBSeK4mJSJFpYF+GJmPOr5G0/oPjw/juiRPC+Lu9k8P4ca3py6p1tRwK285u2xXGd5bS68AAWtvSl4Q74vF8Wf/9zH8O491ntIXxNouXfDt/bPraF1es/fOwbSdvhfFauWtMTEQKzSjp6qSIFJnGxESksHTvpIgUmzd0mHbIlMREZABdnRSRwnIN7ItI0el0Ugpjekd6HRfAWOsJ4+0Wr6+4tWdKamz9oU+GbX+3L65hu2TGmjDeE9SCtQbznEF2ndeJbe+F8W6P68iiT/WCGXEd2MowWh9FujqZecxoZveb2Q4zW121baqZPWNm65Ov6b+pIlIo7pUklufRDPKc+P4IuOSobTcDy9x9DrAs+V5EjhFlt1yPZpCZxNz9eeDotegXAEuS50uAy+rbLRFpJPd8j2Yw3DGxGe6+DcDdt5lZ6uCFmS0CFgGMZfwwdycio8UxygW6OjniPXX3xe4+393nt9Ex0rsTkTrwnI9mMNwktt3MZgIkX3fUr0si0lDH4MD+YB4HFibPFwKP1ac7ItIUCnQoljkmZmY/AS4EppnZFuA7wO3AUjO7BngbuGIkO3nMy1h30lrjua+8N71Wq3VKXP3yh5NXhfGdpYlh/P1SPM45ufVgamx/79iw7Z5D8Xt/qmNbGF9xcHZqbHp7XOcV9Rtg05FpYXxOx7th/LvbL0qNzRp79HW0/nov+kJqzF/617BtXs1ylJVHZhJz96tSQuk/BREpLAfK5fokMTO7H/gqsMPdP51suxX4S2Bn8rJb3P3JJPZt4BqgBPyVuz+VtY/iXIIQkdHhgFu+R7YfMbDOFOAud5+XPPoS2FzgSuDMpM3dZhafhqAkJiKDqFedWEqdaZoFwEPuftjdNwIbgHOyGimJichA+Qf2p5nZ8qrHopx7uN7MXk9ua+wbuD0J2Fz1mi3JtpBuABeRowypfGKXu88f4g7uAf6WShr8W+AO4C9g0EnMMo/3dCQmIgONYImFu29395K7l4F7+fCUcQswq+qlJwPpy0IldCTWDDIGF2xM/GOKSiw2X3NG2PZL4+OlyX7THR/NTx+zP4xH0+HM7Ngbtu2a0R3Gs8o7po5Jn2Zof2lc2HZ8y+EwnvXv/mx7vNzcXz/72dRY16d3h20ntgXHHvW4qOjgdbo6ORgzm9l32yJwOdA3Q87jwINmdidwIjAHeDnr/ZTERGQQdSuxGKzO9EIzm0flWG4TcC2Au68xs6XAWqAXuM7d44ndUBITkcHUqRo/pc70vuD1twG3DWUfSmIiMlCT3FKUh5KYiPTXV+xaEEpiIjJAs0x4mIeSmIgMNIJXJ+tNSUxEBjAdiclQWFt7GC93x/VSkWmrjoTxXaV4abHJLfGUNO0ZS5sdCerEzp+6MWy7M6OWa8WhU8J4V+uh1Nj0lrjOa1ZbXKu1qntWGH/ywCfC+DVffTY19pPFfxy2bf/Zb1Jj5vHPK5cmmissDyUxETlK7hkqmoKSmIgMpCMxESm0cqM7kJ+SmIj0pzoxESk6XZ0UkWIrUBLTfGIiUmjFOhILljazMXG9k7Vm5OuWOF7uDuaXKmfOFhLynriWqxbf/4cfhPHNvZPD+Ls9cTxrabNSMKXLi4cmhW3HtvSE8elj9oXxfeW4ziyyvxwvJxfNkwbZfb/puPWpsUf2/lHYdjTodFJEisvRbUciUnA6EhORItPppIgUm5KYiBSakpiIFJW5TidFpOh0dXJ4allfMavWyuOynYY6tOCcML75srgO7c/OTl+a793errDtawdnh/FJwZxcAJ0Z6zN2e3r93tYjU1JjkF1rFa0rCXB8UEdW8rgu8J2euG9ZsurntvQGa2L+STzX2eQfD6tLQ1KkI7HMin0zu9/MdpjZ6qptt5rZO2a2Mnl8ZWS7KSKjagRXAK+3PLcd/Qi4ZJDtd7n7vOTxZH27JSIN4x+Oi2U9mkFmEnP354E9o9AXEWkWx9iRWJrrzez15HQzdQDBzBaZ2XIzW95DPH4iIs3ByvkezWC4Sewe4DRgHrANuCPthe6+2N3nu/v8NjqGuTsRkcENK4m5+3Z3L7l7GbgXiC+viUixHOunk2Y2s+rby4HVaa8VkYIp2MB+Zp2Ymf0EuBCYZmZbgO8AF5rZPCq5eBNwbT06E9WB1WrMzBPCeM8pM8L4njPGp8YOnhAXBs77yrow/s0Z/yeM7yxNDONtlv65be45Lmx79vhNYfzne+eG8V1jJoTxqM7s/M70ObUA3i+nf+YAJ455L4zftOHrqbEZ4+NarB9+PL7g3uPxgNAbPfHQyd5y+nxkfzX3ubDto0wP43XRJAkqj8wk5u5XDbL5vhHoi4g0i2MpiYnIR4vRPFce81ASE5H+mmi8Kw8tFCIiA9Xp6mTKbYtTzewZM1uffJ1SFfu2mW0wszfM7OI8XVUSE5GB6ldi8SMG3rZ4M7DM3ecAy5LvMbO5wJXAmUmbu80sXpEFJTERGUS9SixSbltcACxJni8BLqva/pC7H3b3jcAGctSgNtWY2OFLPxfGj/+vb6XG5k3cEradO+6FMN5djpd8i6aFWXvopLDtwXJ7GF9/JC7/2Nsblxq0BqOwO47EU/HcsTFeHmzZOf87jP/N1sHmBvhQy7j03/Tdpbg842sT4iXZIP6ZXfux51Njp7bvCNs+cWBmGN+aMVXPjLa9YXx2287U2J92/S5sewyUWMxw920A7r7NzI5Ptp8EvFj1ui3JtlBTJTERaQI+pKuT08xsedX3i9198TD3PFjBZWY6VRITkYHyH4ntcvf5Q3z37WY2MzkKmwn0HRZvAWZVve5kYGvWm2lMTEQGGOHbjh4HFibPFwKPVW2/0sw6zOwUYA6QPm1xQkdiIjJQncbEUm5bvB1YambXAG8DVwC4+xozWwqsBXqB69w9npsdJTEROVodZ6hIuW0R4KKU198G3DaUfSiJiUg/RrEq9pXERGQAJbE0Fi/Ldu7/eCVsflHXmtTYQY+nPsmqA8uq+4lMGhMvz3W4J/6Yd/TEU+1kOb3j3dTY5RNXhm2f/8G5YfwPuv9LGH/zS/E0QssOpRdc7+yN/91XbvxSGF/x9qwwft7sjamxz3S9E7bNqs3rau0O49H0SAAHyum/ry92x/Vzo0JJTEQKTUlMRAqrYLNYKImJyEBKYiJSZJoUUUQKTaeTIlJcTbQcWx5KYiIykJLY4HqO72Tr1elznN066e/C9g/uOS81Nmvs0fOu9ffx9l1h/Kxxvw/jka6WuGbokxPjmqEnDpwcxn/x/qfC+My291Njvzp4Wtj2oVv/Zxj/5l/fGMY//+R/DOP7ZqfPMdDbGf+lTDxrdxj/m7P/JYy3W/ptd++X4jqwqR0Hwvjk1rg2MEtU19jVkr7MHUDrJz+RGrNN8bx5eahiX0QKz8rFyWJKYiLSn8bERKTodDopIsWmJCYiRaYjMREpNiUxESmsoa121HCjmsRaemD89vRP54l988L2p45LX6tvV0+8vuJTH3wmjJ887r0wPqk1vXbnE8F8XgAruyeH8Z/tPDOMnzguXn9xe8+k1Njuns6w7cFgXiuA++66M4zfsT1et/LyqStSY2e1x3Vg75fjdWzWZqzXub88NjXW7fH8cnsz6si6gt8HgB6P/7RaPf3vYHJLXIO27zPHpcZK22v/ky5anVjmakdmNsvMnjOzdWa2xsy+lWyfambPmNn65OvwZxUUkebinu/RBPIs2dYL3OjuZwDnAdeZ2VzgZmCZu88BliXfi8gxYISXbKurzCTm7tvcfUXyfD+wjsrS4guAJcnLlgCXjVAfRWQ0+RAeTWBIJ9BmNhs4G3gJmOHu26CS6Mzs+JQ2i4BFAO2dOuMUKYIiDeznXgHczCYADwM3uHs80lzF3Re7+3x3nz+mIx5kFpHmYOV8j2aQK4mZWRuVBPaAuz+SbN5uZjOT+Exgx8h0UURGlVOogf3M00kzM+A+YJ27V19vfxxYSGVJ8oXAY1nv1XqkTNfmw6nxslvY/ue70qekmTF2f9h2XtfmMP7Gwfhy/apDJ6bGVoz5WNh2XGtPGJ/UHk/l0zkm/TMDmNaW/m8/pSP+f0s0XQ3AK93xv+0/Tf9FGH+7N30I4Z8PnB62XXsw/TMHmJKxVN6qfentD/a2h20Pl+I/je7euGRnUkf8M/3c1PSpn95gZth251nB9Ea/Dpvm1iyD9nnkGRO7ALgaWGVmK5Ntt1BJXkvN7BrgbeCKEemhiIy+YymJufsLVOrfBnNRfbsjIo1WtGJX3XYkIv25a1JEESm44uQwJTERGUinkyJSXA7odFJECq04OWyUk9gHh2j55Wup4X98+oKw+X9b8I+psV9mLGv2xLtxXc++I/GUNNPHpy/hNTGo0wKY2hYv/zUpo95prMVLvr3Xm34nxOGWeMqZUuqF54p3D6dP8wPw6/KcMN5Tbk2NHQ5ikF1ft+fItDB+4ri9qbH9venT9ABs2j81jO/aOyGMd4+P/7ReKKUvpXfJCWvCtuN2pP/MWuJfldx0OikihVbPq5NmtgnYD5SAXnefb2ZTgf8LzAY2Ad9w93hSvxS5750UkY+IkZnF4ovuPs/d5yff120qLyUxEemnUuzquR41qNtUXkpiIjJQOecDppnZ8qrHokHezYGnzezVqni/qbyAQafyykNjYiIywBCOsnZVnSKmucDdtyZzDj5jZv+vtt71pyMxEemvzmNi7r41+boDeBQ4hzpO5aUkJiJHqdw7meeRxcw6zayr7znwZWA1H07lBTmn8krTVKeTp970r2H87te/nt72P78Rtr30hNVhfMW+eN6st4O6od8Gc40BtLXEU2CObzsSxsdm1Eu1t6bPCdaS8b/LckadWGdr3Lesuc6mdqTXyHW1xnNutdQ4dWhr8G9/ee/ssO2M8XHt3ycm7grjvR4fH3x+0pupsfs3nh+2nfF3v0mNbfK4JjG3+k14OAN4tDItIWOAB939Z2b2CnWayqupkpiINIE6Lp7r7m8BZw2yfTd1mspLSUxEBmqSqafzUBITkYGKk8OUxERkICs3yVJGOSiJiUh/Tl8hayEoiYlIP0bNtxSNKiUxERlISSzQEswhVY7XQJz0wIupsd0PxLv96dcuDuPn3vJKGP/q7N+mxj7Vvj1s25ZxbD4243p2Z0tcy9Ud/MJlVTO/cGhWGC9lvMPP3zsjjL/fMy41tv3gxLBtW1D/lke0jumh3nietb2H4vnGWlviP/LuX8RznW1cmz7/3aQn49/FUaEkJiKFpTExESk6XZ0UkQJznU6KSIE5SmIiUnDFOZtUEhORgVQnJiLFdiwlMTObBfwYOIHKQeZid/++md0K/CWwM3npLe7+ZOYeM2rBRkrnwy+F8dUPx+1Xc0pqzD73J2HbQyek10oBdOyO5+Ta//G4/cQ30+eQajkcL0RY/u26MJ7tgxra7guj8SxqtWnPiE+veQ+/q/kdGsYdSsU5n8xzJNYL3OjuK5IZGl81s2eS2F3u/r2R656INMSxdCSWrETStyrJfjNbB5w00h0TkQYqUBIb0hz7ZjYbOBvoOze73sxeN7P7zWxKSptFfcs59RCfNolIE3Cg7PkeTSB3EjOzCcDDwA3uvg+4BzgNmEflSO2Owdq5+2J3n+/u89voqL3HIjLCHLyc79EEcl2dNLM2KgnsAXd/BMDdt1fF7wWeGJEeisjocgo1sJ95JGaVZUruA9a5+51V22dWvexyKsswicixwD3fownkORK7ALgaWGVmK5NttwBXmdk8Knl7E3DtCPSvEPyVVWE8ntQl28T0FboyFef/p9JUmiRB5ZHn6uQLMOjihNk1YSJSQM1zlJWHKvZFpD8HNBWPiBSajsREpLiOvduOROSjxMGbpAYsDyUxERmoSarx81ASE5GBNCYmIoXlrquTIlJwOhITkeJyvNSYyUuHQ0lMRPrrm4qnIJTERGSgApVYDGlSRBE59jngZc/1yMPMLjGzN8xsg5ndXO/+KomJSH9ev0kRzawV+HvgUmAuldlv5tazuzqdFJEB6jiwfw6wwd3fAjCzh4AFwNp67WBUk9h+3tv1rP/091WbpgG7RrMPQ9CsfWvWfoH6Nlz17NvHa32D/bz31LP+02k5Xz7WzJZXfb/Y3RdXfX8SsLnq+y3AubX2sdqoJjF377ecn5ktd/f5o9mHvJq1b83aL1DfhqvZ+ubul9Tx7Qabi7Culz41JiYiI2kLMKvq+5OBrfXcgZKYiIykV4A5ZnaKmbUDVwKP13MHjR7YX5z9koZp1r41a79AfRuuZu5bTdy918yuB54CWoH73X1NPfdhXqB7pEREjqbTSREpNCUxESm0hiSxkb4NoRZmtsnMVpnZyqPqXxrRl/vNbIeZra7aNtXMnjGz9cnXKU3Ut1vN7J3ks1tpZl9pUN9mmdlzZrbOzNaY2beS7Q397IJ+NcXnVlSjPiaW3IbwO+CPqVx+fQW4yt3rVsFbCzPbBMx394YXRprZF4APgB+7+6eTbd8F9rj77cn/AKa4+01N0rdbgQ/c/Xuj3Z+j+jYTmOnuK8ysC3gVuAz4Jg387IJ+fYMm+NyKqhFHYv92G4K7HwH6bkOQo7j788CeozYvAJYkz5dQ+SMYdSl9awruvs3dVyTP9wPrqFSON/SzC/olNWhEEhvsNoRm+kE68LSZvWpmixrdmUHMcPdtUPmjAI5vcH+Odr2ZvZ6cbjbkVLeamc0GzgZeook+u6P6BU32uRVJI5LYiN+GUKML3P2zVO66vy45bZJ87gFOA+YB24A7GtkZM5sAPAzc4O77GtmXaoP0q6k+t6JpRBIb8dsQauHuW5OvO4BHqZz+NpPtydhK3xjLjgb359+4+3Z3L3ll0cJ7aeBnZ2ZtVBLFA+7+SLK54Z/dYP1qps+tiBqRxEb8NoThMrPOZMAVM+sEvgysjluNuseBhcnzhcBjDexLP30JInE5DfrszMyA+4B17n5nVaihn11av5rlcyuqhlTsJ5eQ/xcf3oZw26h3YhBmdiqVoy+o3JL1YCP7ZmY/AS6kMlXLduA7wD8BS4GPAW8DV7j7qA+wp/TtQiqnRA5sAq7tG4Ma5b79AfArYBXQN3PfLVTGnxr22QX9uoom+NyKSrcdiUihqWJfRApNSUxECk1JTEQKTUlMRApNSUxECk1JTEQKTUlMRArt/wPRvxJhCQDpEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a multi-class classification NN\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')]) # the output layer has 10 neurons and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.6523 - accuracy: 0.7732 - val_loss: 0.4051 - val_accuracy: 0.8542\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 1s 675us/step - loss: 0.3849 - accuracy: 0.8620 - val_loss: 0.3986 - val_accuracy: 0.8580\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 1s 698us/step - loss: 0.3453 - accuracy: 0.8750 - val_loss: 0.3532 - val_accuracy: 0.8767\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 1s 695us/step - loss: 0.3195 - accuracy: 0.8842 - val_loss: 0.3519 - val_accuracy: 0.8755\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 1s 674us/step - loss: 0.2939 - accuracy: 0.8928 - val_loss: 0.3226 - val_accuracy: 0.8837\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 1s 674us/step - loss: 0.2810 - accuracy: 0.8967 - val_loss: 0.3378 - val_accuracy: 0.8817\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 1s 674us/step - loss: 0.2680 - accuracy: 0.9004 - val_loss: 0.3360 - val_accuracy: 0.8800\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 1s 691us/step - loss: 0.2606 - accuracy: 0.9049 - val_loss: 0.3433 - val_accuracy: 0.8792\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 1s 710us/step - loss: 0.2439 - accuracy: 0.9096 - val_loss: 0.3357 - val_accuracy: 0.8803\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 1s 698us/step - loss: 0.2359 - accuracy: 0.9120 - val_loss: 0.3264 - val_accuracy: 0.8872\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `fit()` method returns a History object containing the training parameters `history.params`, the list of epochs it went through `history.epoch`, and most importantly a dictionary `history.history` containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 10, 'steps': 1688}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you use this dictionary to create a pandas `DataFrame` and call its `plot()` method, you get the learning curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3484 - accuracy: 0.8787\n",
      "\n",
      "Test accuracy: 0.8787000179290771\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the warning if any\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.4780523e-07, 3.2216924e-08, 2.5034529e-07, 7.7312236e-12,\n",
       "       2.2782420e-07, 2.3626763e-04, 7.0319470e-06, 5.8089001e-03,\n",
       "       9.3531997e-07, 9.9394590e-01], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can read more on MNIST fashion example [here](https://www.tensorflow.org/tutorials/keras/classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Code Examples from keras.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code examples documented on keras.io will work fine with `tf.keras`, but you need to change the imports. For example, consider this keras.io code which can't be run on this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-61f8579950d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moutput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "output_layer = Dense(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You must change the imports like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "output_layer = Dense(10)\n",
    "\n",
    "# Or simply use full paths, if you prefer:\n",
    "from tensorflow import keras\n",
    "output_layer = keras.layers.Dense(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full path approach is more verbose, so you can easily see which packages to use, and to avoid confusion between standard classes and custom classes.\n",
    "\n",
    "In production code, the shorter approach is typically preferred. Many people also use `from tensorflow.keras import layers` followed by `layers.Dense(10)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California House Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to build a regression model for Califronia house pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 920us/step - loss: 1.2698 - val_loss: 85.1545\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.8411 - val_loss: 0.4213\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.4119 - val_loss: 0.4168\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.3887 - val_loss: 0.4041\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3904 - val_loss: 0.4166\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 526us/step - loss: 0.3778 - val_loss: 0.4298\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3878 - val_loss: 0.3994\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.3688 - val_loss: 0.3815\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.3510 - val_loss: 0.3660\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.3803 - val_loss: 0.3869\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.3787 - val_loss: 0.3750\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 525us/step - loss: 0.3565 - val_loss: 0.3535\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3578 - val_loss: 0.3718\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.3472 - val_loss: 0.3906\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3529 - val_loss: 0.3651\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 529us/step - loss: 0.3533 - val_loss: 0.3532\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3919 - val_loss: 0.3551\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.3517 - val_loss: 0.3614\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3538 - val_loss: 0.4493\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.3431 - val_loss: 0.5085\n"
     ]
    }
   ],
   "source": [
    "# build a regression NN\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # output layer with 1 neuron and with None activation function because it's regression\n",
    "])\n",
    "\n",
    "# compile NN with an appropriate regression loss function\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 323us/step - loss: 0.3682\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62588704],\n",
       "       [1.3801625 ],\n",
       "       [3.497154  ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if training lasts several hours? This is quite common, especially when training on large datasets.\n",
    "\n",
    "In this case, you should not only save your model at the end of training, but also save **checkpoints** at regular intervals during training, to avoid losing everything if your computer crashes.\n",
    "\n",
    "How can you tell the `fit()` method to save **checkpoints**? Use **callbacks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` method accepts a `callbacks` argument that lets you specify a list of objects that Keras will call at the start and end of training, at the start and end of each epoch, and even before and after processing each batch. For example, the `ModelCheckpoint` callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you use a validation set during training, you can set `save_best_only=True` when creating the `ModelCheckpoint` .\n",
    "\n",
    "In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a simple way to implement **early stopping**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoint\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 781us/step - loss: 4.0356 - val_loss: 1.5853\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.8443 - val_loss: 0.7261\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 583us/step - loss: 0.6946 - val_loss: 0.6579\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.6113 - val_loss: 0.6013\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 640us/step - loss: 0.5734 - val_loss: 0.5675\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.5446 - val_loss: 0.5484\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 568us/step - loss: 0.5273 - val_loss: 0.5171\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 615us/step - loss: 0.4935 - val_loss: 0.4987\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.4748 - val_loss: 0.4925\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 575us/step - loss: 0.4735 - val_loss: 0.4822\n"
     ]
    }
   ],
   "source": [
    "# train with callbacks and validation_data\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 388us/step - loss: 0.4748\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Another way to implement **early stopping** is to simply use the `EarlyStopping` callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the `patience` argument), and it will optionally roll back to the best model.\n",
    "\n",
    "> You can combine both callbacks to save checkpoints of your model (in case your computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.4652 - val_loss: 0.5033\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 575us/step - loss: 0.4214 - val_loss: 0.4812\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 572us/step - loss: 0.4361 - val_loss: 0.4823\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.4301 - val_loss: 0.4625\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 559us/step - loss: 0.4121 - val_loss: 0.4708\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.4181 - val_loss: 0.4589\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.4002 - val_loss: 0.4862\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3935 - val_loss: 0.4705\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.3986 - val_loss: 0.4694\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.4071 - val_loss: 0.4825\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.4004 - val_loss: 0.4529\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3870 - val_loss: 0.4608\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3887 - val_loss: 0.4508\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3903 - val_loss: 0.4346\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.3764 - val_loss: 0.4780\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.3991 - val_loss: 0.4589\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3714 - val_loss: 0.4389\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3766 - val_loss: 0.4528\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.3783 - val_loss: 0.4440\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.3628 - val_loss: 0.4331\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3823 - val_loss: 0.4622\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3724 - val_loss: 0.4404\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3644 - val_loss: 0.4339\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3789 - val_loss: 0.4312\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3621 - val_loss: 0.4208\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 566us/step - loss: 0.3633 - val_loss: 0.4306\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3654 - val_loss: 0.4193\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3613 - val_loss: 0.4166\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3405 - val_loss: 0.4159\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3583 - val_loss: 0.4269\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 559us/step - loss: 0.3630 - val_loss: 0.4335\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3709 - val_loss: 0.4274\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3491 - val_loss: 0.4294\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.3644 - val_loss: 0.4132\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.3517 - val_loss: 0.4078\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3652 - val_loss: 0.4229\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.3641 - val_loss: 0.4156\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3416 - val_loss: 0.4206\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3385 - val_loss: 0.4150\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3516 - val_loss: 0.4104\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 576us/step - loss: 0.3494 - val_loss: 0.4146\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.3500 - val_loss: 0.4109\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3422 - val_loss: 0.4036\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 554us/step - loss: 0.3486 - val_loss: 0.4024\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3481 - val_loss: 0.3995\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3604 - val_loss: 0.3911\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.3541 - val_loss: 0.3964\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3450 - val_loss: 0.3897\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 554us/step - loss: 0.3550 - val_loss: 0.3880\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.3520 - val_loss: 0.3836\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.3433 - val_loss: 0.3933\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3628 - val_loss: 0.3885\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3443 - val_loss: 0.3832\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3404 - val_loss: 0.3886\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.3388 - val_loss: 0.3833\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3481 - val_loss: 0.3814\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3380 - val_loss: 0.3816\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.3244 - val_loss: 0.3848\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3421 - val_loss: 0.3897\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.3292 - val_loss: 0.3869\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3428 - val_loss: 0.3806\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.3187 - val_loss: 0.3751\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 559us/step - loss: 0.3358 - val_loss: 0.3764\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 582us/step - loss: 0.3462 - val_loss: 0.3758\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 554us/step - loss: 0.3435 - val_loss: 0.3784\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 554us/step - loss: 0.3398 - val_loss: 0.3750\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3318 - val_loss: 0.3755\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.3408 - val_loss: 0.3743\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3159 - val_loss: 0.3870\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3304 - val_loss: 0.3754\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3283 - val_loss: 0.3725\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.3379 - val_loss: 0.3736\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3218 - val_loss: 0.3775\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.3383 - val_loss: 0.3763\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3284 - val_loss: 0.3781\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.3358 - val_loss: 0.3787\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.3372 - val_loss: 0.3724\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 566us/step - loss: 0.3224 - val_loss: 0.3873\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 579us/step - loss: 0.3501 - val_loss: 0.3715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.3265 - val_loss: 0.3685\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 568us/step - loss: 0.3202 - val_loss: 0.3693\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.3328 - val_loss: 0.3727\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 566us/step - loss: 0.3201 - val_loss: 0.3672\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3350 - val_loss: 0.3675\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3271 - val_loss: 0.3685\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3337 - val_loss: 0.3628\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.3245 - val_loss: 0.3719\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 568us/step - loss: 0.3239 - val_loss: 0.3637\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 589us/step - loss: 0.3188 - val_loss: 0.3755\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.3338 - val_loss: 0.3689\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3297 - val_loss: 0.3681\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 575us/step - loss: 0.3341 - val_loss: 0.3631\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.3253 - val_loss: 0.3669\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 586us/step - loss: 0.3449 - val_loss: 0.3664\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 554us/step - loss: 0.3242 - val_loss: 0.3700\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.3204 - val_loss: 0.3580\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.3238 - val_loss: 0.3689\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3194 - val_loss: 0.3539\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3217 - val_loss: 0.3648\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3223 - val_loss: 0.3720\n",
      "162/162 [==============================] - 0s 332us/step - loss: 0.3542\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "# after 10 epochs, if there is not a significant improvement, stop training\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you need extra control, you can easily write your own custom callbacks. As an example of how to do that, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect overfitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 635us/step - loss: 0.3236 - val_loss: 0.3555\n",
      "\n",
      "val/train: 1.10\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neat feature of Tensorflow and Keras is visulaization through Tensorboard. The following code shows how you can visualiza your training using Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.3234 - val_loss: 0.3639\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.3230 - val_loss: 0.3620\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3227 - val_loss: 0.3598\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3226 - val_loss: 0.3590\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.3222 - val_loss: 0.3596\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.3219 - val_loss: 0.3569\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3218 - val_loss: 0.3557\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3214 - val_loss: 0.3646\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3211 - val_loss: 0.3525\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 604us/step - loss: 0.3207 - val_loss: 0.3683\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 554us/step - loss: 0.3207 - val_loss: 0.3606\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3201 - val_loss: 0.3574\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3202 - val_loss: 0.3579\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3195 - val_loss: 0.3585\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.3195 - val_loss: 0.3579\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.3191 - val_loss: 0.3601\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3190 - val_loss: 0.3557\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3187 - val_loss: 0.3539\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.3184 - val_loss: 0.3577\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3182 - val_loss: 0.3494\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.3180 - val_loss: 0.3544\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 554us/step - loss: 0.3175 - val_loss: 0.3567\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 587us/step - loss: 0.3174 - val_loss: 0.3598\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.3170 - val_loss: 0.3547\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 573us/step - loss: 0.3168 - val_loss: 0.3528\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.3164 - val_loss: 0.3478\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 573us/step - loss: 0.3164 - val_loss: 0.3462\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 609us/step - loss: 0.3159 - val_loss: 0.3480\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.3158 - val_loss: 0.3462\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.3150 - val_loss: 0.3540\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard Visualization\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, run the following command at the root of the project directory where `my_logs` has been saved (or from anywhere else, as long as you point to the appropriate log directory):\n",
    "\n",
    "> `$ tensorboard --logdir=./my_logs --port=6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> And finally, once the server is up, you can open a web browser and go to:\n",
    "\n",
    "> http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-1 has 10 points**.\n",
    "\n",
    "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
    "\n",
    "- Imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k etc.\n",
    "\n",
    "- How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc.\n",
    "\n",
    "**Hint**: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data with at least 6 data points for x and y, where y is in the hundreds of thousands\n",
    "xs = np.array([1.0, 2.0, 5.0, 7.0, 10.0, 15.0], dtype=float)\n",
    "ys = np.array([1.0, 1.5, 3.0, 4.0, 5.5, 8.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with one layer and one neuron\n",
    "layer_1 = keras.layers.Dense(units=1, input_shape=[1])\n",
    "model = tf.keras.Sequential([layer_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for regression\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 53.8120\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.0722\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0156\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2296\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1265\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1118\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1086\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1070\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1055\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1041\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1027\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1013\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0999\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0986\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0973\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0960\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0947\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0934\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0922\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0909\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0897\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0885\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0873\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0861\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0850\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0838\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0827\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0816\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0805\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0794\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0784\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0773\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0763\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0753\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0742\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0732\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0723\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0713\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0703\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.0694\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0685\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0675\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0666\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0649\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0640\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0631\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0623\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0614\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0606\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0598\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0590\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0582\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0574\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0567\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0559\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0552\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0544\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0537\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0530\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0523\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0516\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0502\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0495\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0488\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0482\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0475\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0469\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0463\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0456\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0450\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0444\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0438\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0432\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0427\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0421\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0415\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0410\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0404\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0399\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0393\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0388\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0383\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0378\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0373\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0368\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0363\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0358\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0353\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0348\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0344\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0339\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0335\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0330\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0326\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0321\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0317\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0313\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0309\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0304\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0300\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0296\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0292\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0288\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0284\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0281\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0277\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0273\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0270\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0266\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0262\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0259\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0255\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0252\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0245\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0242\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0235\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0232\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0229\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0226\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0223\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0220\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0206\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0198\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0195\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0190\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0185\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0180\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0177\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0173\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0170\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0134\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0132\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0130\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0128\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0126\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0125\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0123\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0121\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0120\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0118\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0117\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0115\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0114\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0112\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0110\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0108\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0106\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0105\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0101\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0093\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0089\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0084\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0083\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0082\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0080\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0079\n",
      "Epoch 202/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0077\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0076\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0075\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0074\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0073\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0070\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0067\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0066\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0065\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0064\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0064\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0063\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0062\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0061\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0060\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0059\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0059\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0058\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0057\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0056\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0055\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0053\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0053\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0052\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0050\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0047\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0045\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0045\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0044\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0042\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0042\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0041\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0041\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0040\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0040\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0039\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0038\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0037\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0035\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0033\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0033\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0032\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0032\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0031\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0030\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.0029\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0028\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0027\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0027\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0026\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0026\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0026\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0025\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0018\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0018\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0016\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0015\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0015\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0014\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0013\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0013\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0012\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0010\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9761e-04\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8421e-04\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7101e-04\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5798e-04\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4513e-04\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3244e-04\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1992e-04\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.0759e-04\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9540e-04\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8339e-04\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7153e-04\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5984e-04\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.4830e-04\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3692e-04\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.2569e-04\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1460e-04\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0367e-04\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9289e-04\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8225e-04\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7176e-04\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6139e-04\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5118e-04\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.4109e-04\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3115e-04\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.2134e-04\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1166e-04\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0211e-04\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9269e-04\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8339e-04\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7422e-04\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6517e-04\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5625e-04\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4745e-04\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3875e-04\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3019e-04\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2173e-04\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1338e-04\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0515e-04\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9703e-04\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8902e-04\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.8112e-04\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.7331e-04\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6562e-04\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5803e-04\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5054e-04\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4315e-04\n",
      "Epoch 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3587e-04\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.2868e-04\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2158e-04\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.1458e-04\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.0768e-04\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0086e-04\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.9414e-04\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8751e-04\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8097e-04\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7452e-04\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6815e-04\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6187e-04\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.5567e-04\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4955e-04\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4352e-04\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.3757e-04\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3170e-04\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2590e-04\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.2019e-04\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1455e-04\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0899e-04\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0350e-04\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9808e-04\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9274e-04\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8747e-04\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8227e-04\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7714e-04\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.7208e-04\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6709e-04\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6217e-04\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5730e-04\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5251e-04\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4778e-04\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4311e-04\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3850e-04\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.3396e-04\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2948e-04\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2506e-04\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2070e-04\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1640e-04\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1215e-04\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0796e-04\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0383e-04\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.9975e-04\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9573e-04\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9176e-04\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8785e-04\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8398e-04\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8017e-04\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7641e-04\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7270e-04\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6904e-04\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6543e-04\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6187e-04\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5836e-04\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5489e-04\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5147e-04\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4809e-04\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4476e-04\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.4148e-04\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3824e-04\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3504e-04\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.3189e-04\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2877e-04\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2571e-04\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2268e-04\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1969e-04\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.1674e-04\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1383e-04\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1096e-04\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0813e-04\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0534e-04\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0258e-04\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9986e-04\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9718e-04\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9454e-04\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9193e-04\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8935e-04\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8681e-04\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.8430e-04\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.8183e-04\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 1.7939e-04\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7698e-04\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7461e-04\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.7226e-04\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6995e-04\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6767e-04\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6542e-04\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.6320e-04\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6101e-04\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.5885e-04\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5672e-04\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5462e-04\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.5254e-04\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5049e-04\n",
      "Epoch 495/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4848e-04\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4648e-04\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4452e-04\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4258e-04\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4066e-04\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3878e-04\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3692e-04\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3508e-04\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3326e-04\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3148e-04\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2971e-04\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2797e-04\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2625e-04\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2456e-04\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2289e-04\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2124e-04\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1961e-04\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1801e-04\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1642e-04\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1486e-04\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1332e-04\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1180e-04\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1030e-04\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0882e-04\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0736e-04\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0592e-04\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0449e-04\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0310e-04\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0171e-04\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0035e-04\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8999e-05\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7672e-05\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6362e-05\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5067e-05\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3792e-05\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.2534e-05\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1291e-05\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0066e-05\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8857e-05\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7665e-05\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6490e-05\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.5328e-05\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4182e-05\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3053e-05\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1939e-05\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0839e-05\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.9755e-05\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8685e-05\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7628e-05\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6586e-05\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5559e-05\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4546e-05\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3546e-05\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.2556e-05\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1584e-05\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0624e-05\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9674e-05\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8739e-05\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7817e-05\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.6906e-05\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6008e-05\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.5125e-05\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4249e-05\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3388e-05\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2537e-05\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.1698e-05\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.0871e-05\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 884us/step - loss: 6.0052e-05\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9247e-05\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8451e-05\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7667e-05\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6893e-05\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.6129e-05\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5377e-05\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4633e-05\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3899e-05\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.3176e-05\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2465e-05\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1760e-05\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1064e-05\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0380e-05\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9703e-05\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9037e-05\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8380e-05\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7730e-05\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.7089e-05\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6457e-05\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5834e-05\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5218e-05\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4611e-05\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.4014e-05\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3423e-05\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.2839e-05\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.2265e-05\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1697e-05\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1138e-05\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.0587e-05\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0040e-05\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9503e-05\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8975e-05\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8451e-05\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7935e-05\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7426e-05\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6923e-05\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6428e-05\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5940e-05\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.5458e-05\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4982e-05\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.4511e-05\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4049e-05\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3593e-05\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3142e-05\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2697e-05\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.2257e-05\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1825e-05\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1398e-05\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.0977e-05\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0561e-05\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0150e-05\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9745e-05\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9346e-05\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8953e-05\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8564e-05\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8181e-05\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7803e-05\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7430e-05\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7061e-05\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6698e-05\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6340e-05\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5986e-05\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.5638e-05\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.5293e-05\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.4954e-05\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4620e-05\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4289e-05\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3963e-05\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.3642e-05\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3324e-05\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3010e-05\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2703e-05\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2398e-05\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2098e-05\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1800e-05\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1507e-05\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1219e-05\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 2.0934e-05\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0653e-05\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0377e-05\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0103e-05\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9834e-05\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 487us/step - loss: 1.9567e-05\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9305e-05\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.9045e-05\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8790e-05\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8538e-05\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8289e-05\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8044e-05\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7802e-05\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7562e-05\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7327e-05\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7094e-05\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6864e-05\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 501us/step - loss: 1.6639e-05\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6416e-05\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6196e-05\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5978e-05\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.5763e-05\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5552e-05\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5343e-05\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5137e-05\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4935e-05\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4734e-05\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4536e-05\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4341e-05\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.4149e-05\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3959e-05\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3772e-05\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3587e-05\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.3405e-05\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3224e-05\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3046e-05\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2872e-05\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2700e-05\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2529e-05\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2361e-05\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2195e-05\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2031e-05\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1869e-05\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1710e-05\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1553e-05\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1398e-05\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1245e-05\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1095e-05\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0946e-05\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0798e-05\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0654e-05\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0510e-05\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0370e-05\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0230e-05\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0093e-05\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9574e-06\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8239e-06\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6926e-06\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5619e-06\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4344e-06\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3070e-06\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1825e-06\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0590e-06\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.9374e-06\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8177e-06\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6996e-06\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.5827e-06\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.4676e-06\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3541e-06\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2416e-06\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1309e-06\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.0218e-06\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.9143e-06\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8085e-06\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.7035e-06\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6003e-06\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.4979e-06\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3976e-06\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2981e-06\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2002e-06\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1038e-06\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0081e-06\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9146e-06\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8210e-06\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7305e-06\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6397e-06\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5503e-06\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4624e-06\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3757e-06\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2898e-06\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2059e-06\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1224e-06\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0402e-06\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9594e-06\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.8792e-06\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.8009e-06\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7229e-06\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6461e-06\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5700e-06\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4956e-06\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.4217e-06\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.3488e-06\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2773e-06\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2061e-06\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1369e-06\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0676e-06\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9998e-06\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9322e-06\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.8663e-06\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.8007e-06\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.7362e-06\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6727e-06\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6101e-06\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.5485e-06\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4873e-06\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4269e-06\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.3674e-06\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3090e-06\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2513e-06\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1941e-06\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1381e-06\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0826e-06\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0279e-06\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.9739e-06\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9203e-06\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8674e-06\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8155e-06\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.7648e-06\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7139e-06\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6642e-06\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6152e-06\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.5665e-06\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5187e-06\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4714e-06\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4250e-06\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3786e-06\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.3331e-06\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2888e-06\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2446e-06\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2011e-06\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1581e-06\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1159e-06\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.0738e-06\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0330e-06\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9921e-06\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9519e-06\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9118e-06\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8731e-06\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.8346e-06\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7969e-06\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7593e-06\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7223e-06\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6857e-06\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6496e-06\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6138e-06\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5785e-06\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5441e-06\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5099e-06\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4763e-06\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4430e-06\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4103e-06\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3781e-06\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3461e-06\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3143e-06\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2836e-06\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 878us/step - loss: 2.2530e-06\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2227e-06\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1929e-06\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1636e-06\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1344e-06\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1059e-06\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0776e-06\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0496e-06\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0221e-06\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9950e-06\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9683e-06\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9415e-06\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9157e-06\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8903e-06\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8646e-06\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8396e-06\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8149e-06\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7906e-06\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7666e-06\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7431e-06\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7194e-06\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6967e-06\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6736e-06\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6512e-06\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6290e-06\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6072e-06\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5856e-06\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.5645e-06\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5432e-06\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5227e-06\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5021e-06\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4822e-06\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4622e-06\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.4425e-06\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4232e-06\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4041e-06\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3854e-06\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3669e-06\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3483e-06\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3301e-06\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3124e-06\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2948e-06\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2773e-06\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2602e-06\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2433e-06\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2266e-06\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2103e-06\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1938e-06\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1779e-06\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1620e-06\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1466e-06\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1311e-06\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1159e-06\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1009e-06\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0861e-06\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0716e-06\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0573e-06\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0429e-06\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0290e-06\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0151e-06\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0017e-06\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8805e-07\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.7482e-07\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6188e-07\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4904e-07\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3621e-07\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2367e-07\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1110e-07\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9896e-07\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8699e-07\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7487e-07\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6332e-07\n",
      "Epoch 877/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5168e-07\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4012e-07\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2907e-07\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1788e-07\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0695e-07\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9609e-07\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.8542e-07\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7466e-07\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6444e-07\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5419e-07\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4391e-07\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3407e-07\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2418e-07\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1458e-07\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0493e-07\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9543e-07\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8609e-07\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7691e-07\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6779e-07\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5883e-07\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5008e-07\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4119e-07\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3266e-07\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.2429e-07\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1577e-07\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.0759e-07\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.9940e-07\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.9151e-07\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8351e-07\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7568e-07\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6789e-07\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.6027e-07\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5277e-07\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.4533e-07\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.3812e-07\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.3071e-07\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2370e-07\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1677e-07\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0969e-07\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.0291e-07\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9608e-07\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8957e-07\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8290e-07\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7633e-07\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7011e-07\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6357e-07\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.5754e-07\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.5138e-07\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4512e-07\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.3943e-07\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.3335e-07\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2759e-07\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.2188e-07\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.1610e-07\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1060e-07\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0495e-07\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9966e-07\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9420e-07\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8905e-07\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8374e-07\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7857e-07\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7346e-07\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6859e-07\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6366e-07\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5873e-07\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.5394e-07\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4905e-07\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.4439e-07\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3983e-07\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3527e-07\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 500us/step - loss: 3.3080e-07\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 3.2643e-07\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2199e-07\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1755e-07\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1338e-07\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0911e-07\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0504e-07\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0086e-07\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.9698e-07\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9292e-07\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8895e-07\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8507e-07\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.8122e-07\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.7756e-07\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7387e-07\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7005e-07\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6647e-07\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6291e-07\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.5939e-07\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 2.5594e-07\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.5236e-07\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4904e-07\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 499us/step - loss: 2.4575e-07\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4239e-07\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.3919e-07\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3592e-07\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3282e-07\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2965e-07\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2661e-07\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.2353e-07\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2054e-07\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1769e-07\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1468e-07\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.1180e-07\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0893e-07\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0611e-07\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.0335e-07\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0061e-07\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.9798e-07\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.9530e-07\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9271e-07\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.9017e-07\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8763e-07\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.8498e-07\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.8255e-07\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8012e-07\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7762e-07\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7530e-07\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7300e-07\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.7061e-07\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6841e-07\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6608e-07\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6380e-07\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6167e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f8a30a02b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with 1000 epochs\n",
    "model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.9997919]]\n"
     ]
    }
   ],
   "source": [
    "# predict the price for 7-bedroom house price\n",
    "print(model.predict([7.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-2 has 20 points**.\n",
    "\n",
    "In this notebook you learned how to do classification using Fashion MNIST, a data set containing items of clothing, and a similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy using `callbacks`.\n",
    "\n",
    "- **Requirements**:\n",
    "1. It should succeed in less than 10 epochs.\n",
    "2. When it reaches 99% or greater it should print out the string `\"Reached 99% accuracy so cancelling training!\"` as specified in the `myCallback` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.99):\n",
    "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load data\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalize data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model - be careful about the activation functions of the hidden layer and output layer\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - be careful to use the correct loss for multi-class classification, metrics should be 'accuracy'\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3522 - accuracy: 0.8931\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0895 - accuracy: 0.9740\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0693 - accuracy: 0.9804\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0543 - accuracy: 0.9846\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0458 - accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0394 - accuracy: 0.9895\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0347 - accuracy: 0.9910\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001F8A3396C10>\n"
     ]
    }
   ],
   "source": [
    "# train model with 10 epochs (will stop earlier) and callbacks\n",
    "# Note: Your output should include the message: \"Reached 99% accuracy so cancelling training!\"\n",
    "# The output should also include:\n",
    "# <tensorflow.python.keras.callbacks.History at MEMORY_ADDRESS> \n",
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] - [Tensorflow Website](https://www.tensorflow.org/)\n",
    "- [2] - [Tensorflow Tutorials](https://www.tensorflow.org/tutorials)\n",
    "- [3] - [Hands-On ML Textbook 2nd Edition](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "- [4] - [DeepLearning.AI TensorFlow Developer Professional Certificate - Course-1](https://www.coursera.org/professional-certificates/tensorflow-in-practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your notebook ```Lastname-tf-notebook.ipynb```. Submit the file using the ```tf-notebook``` link on Blackboard.\n",
    "\n",
    "- tf-notebook has a total of 30 points which will be counted towards the \"Assignment\" section of your final grade.\n",
    "\n",
    "- **RUN ALL CELLS REQUIREMENT**: You must run all cells to get the outputs and then attempt exercises. Otherwise, if any cell is not run with the correct output, your notebook gets ZERO even if you've completed the exercises.\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * verification of correct installation of Tensorflow\n",
    "  * error-free running of all the cells - all outputs and plots must be included - any missing output would cause the notebook to get ZERO!\n",
    "  * correct answers to the exercises - Exercise-1 [10 points], Exercise-2 [20 points]\n",
    "  \n",
    "<font color=red><b>Due Date: Tuesday April 20th, 11:59PM</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
